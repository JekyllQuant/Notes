{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High Priority\n",
    "1. CHECK AGAIN TS/GR SOLUTIONS\n",
    "1. Hyperparameter Optimization\n",
    "    - BayesSearchCV\n",
    "1. Model Evaluation + Model Ensembling + Feature Selection (Feature Importance)\n",
    "    - Model Ensembling:\n",
    "        - How to specialize models?\n",
    "        - Split dataset by volatility regimes?\n",
    "            - Split dataset by looking at quantiles of std(mid)\n",
    "            - 3 quantiles: low / normal / high volatility regimes\n",
    "            - Do feature selection and build a model for each regime\n",
    "        - Do model averaging/ensempling using Linear Regression/Ridge Regression?\n",
    "    - Cumulative $R^2$ Plotting:\n",
    "        - Implement cumulative $R^2$ in a time-series cross-validation setting\n",
    "        - Plot Cumulative $R^2$ for various models for different cv-folds and understand which ones are the best models for each fold\n",
    "        - For each model/set of features for all the (5) folds of the CV set\n",
    "        - Use learning_curve (scikit-learn)?\n",
    "    - Check how to combine different models built on different set of features\n",
    "        - How to select the features for each model?\n",
    "    - Feature Selection (Feature Importance):\n",
    "        - Check RFECV to do Feature Selection\n",
    "        - Do Feature Importance with XGBoost using Cross-Validation:\n",
    "            - Does the importance change on different folds? If yes, probably you need to use different features for different periods\n",
    "1. Features:\n",
    "    1. Bukosabino \"Blackmagic\"\n",
    "        - Check Bukosabino GitHub \"Blackmagic\"\n",
    "        - Use his standardization techniques as well? (same file of Blackmagic)\n",
    "    1. Use Robust Z-Score?\n",
    "        - Use by Sam (GR)\n",
    "        - $\\text{Robust Z-Score} = \\frac{x-\\text{median}}{\\text{MAD (Median Abs Deviation)}}$\n",
    "    1. New Features\n",
    "        - Volatility / Std\n",
    "        - Diffs\n",
    "        - Sum\n",
    "        - Ratios\n",
    "    1. Select Different Features:\n",
    "        - Select less order book levels and see if anything changes\n",
    "    1. Reduce Memory Footprint:\n",
    "        - Try using Differences/Returns in time instead of Z-Score\n",
    "    1. Transform Features:\n",
    "        - Check if features are non-normally distributed (using an histogram)\n",
    "        - Apply Log/Box-Cox Transformation?\n",
    "1. Cross-Validation\n",
    "    - Change $R^2$ to use $\\overline{y}=0$ (true metric used by XTX)\n",
    "    - Change Cross-Validation Method:\n",
    "        - Test other CV strategies to get a better estimate for OOS\n",
    "        - Change TimeSeriesSplit to something else\n",
    "        - Test Stratified Sampling / StratifiedKFold\n",
    "    - Shuffling dataset gives better $R^2$: Is it because I use the future to forecast the present?\n",
    "    - Adding lags doens't improve $R^2$: Is it because samples are independent?\n",
    "    - Select best features for each fold + Train single model on each fold/feature set + Ensemble\n",
    "1. MAE / Huber Loss\n",
    "    - Test Huber Loss with XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low Priority\n",
    "1. Remove Outliers\n",
    "1. Test Neural Networks\n",
    "1. New Models:\n",
    "    - Fix models that aren't working + Test new models:\n",
    "        - ExtraTrees\n",
    "        - Random Forests\n",
    "        - GBM\n",
    "        - Neural Networks\n",
    "        - Lasso\n",
    "1. Feature Selection:\n",
    "    - CCF & Stationary Data?\n",
    "        - You should have checked if data was stationary before coing CCF (Cross-Correlation Function)\n",
    "1. Multi-class Classification:\n",
    "    - Treat problem as multi-class classification problem?\n",
    "1. Train on true (reconstructed) $y$, not winsorized $y$\n",
    "    - clip prediction output to $[-5,5]$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# BayesSearchCV\n",
    "- Bayes Optimization offered by `Scikit-Optimize`/`skopt`\n",
    "- Check file `skopt_sklearn-gridsearchcv-replacement.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Scikit-Learn GridSearchCV Interface\n",
    "- Check interesting options offered by GridSearchCV to be replicated with BayesSearchCV:\n",
    "    - plotting\n",
    "    - scores\n",
    "    - partial results via callbacks\n",
    "    - save results to be resumed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progress monitoring/control via `callbacks`\n",
    "\n",
    "Monitor progress of BayesSearchCV with event handler called on every step of subspace exploration\n",
    "- n_jobs=1: event handler called on every evaluation of model configuration\n",
    "- n_jobs>1 (parallel mode): event handler called when n_jobs model configurations are evaluated in parallel\n",
    "- Exploration can be stopped if callback returns True. E.g, stop exploration early if accuracy obtained is sufficiently high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchcv = BayesSearchCV(\n",
    "    SVC(gamma='scale'),\n",
    "    search_spaces={'C': (0.01, 100.0, 'log-uniform')},\n",
    "    n_iter=10,\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "# callback handler\n",
    "def on_step(optim_result):\n",
    "    score = searchcv.best_score_\n",
    "    print(\"best score: %s\" % score)\n",
    "    if score >= 0.98:\n",
    "        print('Interrupting!')\n",
    "        return True\n",
    "\n",
    "searchcv.fit(X, y, callback=on_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bukosabino (GR-29th)\n",
    "- https://medium.com/@bukosabino/financial-forecasting-challenge-by-g-research-8792c5344ae9\n",
    "- https://github.com/bukosabino/financial-forecasting-challenge-gresearch\n",
    "\n",
    "### Feature Engineering\n",
    "- Black magic: I added **rolling_mean**, **inverse_rolling_mean**, **diffs**, **cumsum** and **shift** for all features order by 'Stock' with different periods. When I included them my results grew up greatly.\n",
    "\n",
    "### Models\n",
    "- Tuned different boosting models like **XGBoost** and **LightGBM**\n",
    "- XGBoost had always better results than LightGBM.\n",
    "- **Stacked the best models** using different weights\n",
    "\n",
    "### Ideas with Bad Results:\n",
    "- **RNN/Recurrent Neural Networks** using Keras library (**LSTMs** with different approaches)\n",
    "- Delete and/or **clip outliers** values through some observations and using statistical methods like standard deviation\n",
    "- feature engineering with decomposition methods such as **PCA**, **SVD** or **TSNE** for different groups of features from the original dataset\n",
    "- **Data normalization**\n",
    "- **ExtraTreesRegressor**, **RandomForestRegressor**, and different **linear regressions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection: Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "print(\"Features sorted by their score:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), feature_names), reverse=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py373_xtx_venv",
   "language": "python",
   "name": "py373_xtx_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
